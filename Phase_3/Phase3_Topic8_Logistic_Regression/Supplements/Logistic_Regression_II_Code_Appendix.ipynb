{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7bba7fc",
   "metadata": {},
   "source": [
    "# Logistic Regression II Code Appendix\n",
    "\n",
    "## Logistic Regression with Different Hyperparameters\n",
    "\n",
    "When building a logistic regression model, there is a set of hyperparameters that can improve the performance of the model.  Here is a list of them with a brief description of each one.\n",
    "\n",
    "Hyperparameters:\n",
    "\n",
    "- penalty: Apply different regularization to the model. Note that regularization is applied by default ('l2').\n",
    "- tol: Stopping criteria for gradient descent.\n",
    "- C: Inverse of regularization strength, with default = 1.0. The smaller values specify stronger regularization.\n",
    "- solver: Algorithm to use in the optimization problem, with default = 'lbfgs'.\n",
    "- max_iter: Maximum number of iterations taken for the solvers to converge, with default = 100.\n",
    "\n",
    "Resource: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Python Code:\n",
    "    \n",
    "``` Python\n",
    "# Import dependencies\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, confusion_matrix, accuracy_score\n",
    "\n",
    "# Setting hyperparameters for the model\n",
    "penalty = 'l1'         # regularization penalty\n",
    "tolerance = 1e-2       # early stopping criteria\n",
    "strength = 10          # regularization strength\n",
    "solver = 'liblinear'   # algorithm to use in the optimization problem\n",
    "max_iter = 100         # max number of iterations\n",
    "multi_class = 'ovr'    # for solving binary class problem\n",
    "\n",
    "# Creating the classifier object\n",
    "clf = LogisticRegression(penalty=penalty,\n",
    "                         tol=tolerance,\n",
    "                         C=strength,\n",
    "                         solver=solver,\n",
    "                         max_iter=max_iter,\n",
    "                         multi_class=multi_class)\n",
    "\n",
    "# Fitting the data to the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction of the class based on predicted probability\n",
    "prob_hat = clf.predict_proba(X_train)\n",
    "y_hat = [int(i[1] > 0.6) for i in prob_hat]\n",
    "\n",
    "# Log loss from the model prediction\n",
    "log_loss(y_train, prob_hat)\n",
    "\n",
    "# Accuracy score \n",
    "accuracy_score(y_train, y_hat)\n",
    "\n",
    "# Confusion matrix \n",
    "confusion_matrix(y_train, y_hat)\n",
    "```\n",
    "\n",
    "## Evaluate the Model with Cross-Validation\n",
    "\n",
    "Resource: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n",
    "\n",
    "Python Code:\n",
    "\n",
    "``` Python\n",
    "# Import dependencies\n",
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(estimator=clf,\n",
    "                           X=X_train,\n",
    "                           y=y_train,\n",
    "                           cv=5,\n",
    "                           scoring=['accuracy'],\n",
    "                           return_train_score=True)\n",
    "\n",
    "# Extract train accuracy from cv_results\n",
    "cv_results['train_accuracy']\n",
    "\n",
    "# Extract test accuracy from cv_results\n",
    "cv_results['test_score']\n",
    "```\n",
    "\n",
    "## Logistic Regression Model for Multi-Class Problem\n",
    "\n",
    "Python Code:\n",
    "\n",
    "``` Python\n",
    "# Import dependencies\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Multi-class classifier\n",
    "clf = LogisticRegression(solver='saga',\n",
    "                         multi_class='multinomial')\n",
    "\n",
    "# Fitting the data into the model\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Note: When solving for multi-class problems with logistic regression, we need to make sure to select the correct solver for the problem. Some solvers are better at handling multinomial loss than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7df67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
