{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Classification Metrics: ROC and AUC\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "DS-NTL-010824\n",
    "<p>Phase 3</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objectives\n",
    "- Calculate and interpret probability estimates\n",
    "- Adjust the threshold of a logistic regression model\n",
    "- Visualize, calculate and interpret the AUC-ROC metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report # plot_confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What is the issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Related to (basically the same as) concerns around Neyman-Pearson testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"Images/neyman_small.png\" width = 900 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\alpha$ is the false positive rate (reject null when null is true)\n",
    "- $\\beta$ is false negative rate (accept null when null is false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Dependent on $t_{crit}$ OR:\n",
    "    - the significance level $\\alpha$\n",
    "    - the probability **threshold**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Obvious connection\n",
    "- Hypothesis testing\n",
    "- Probabilistic classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\alpha$ and $\\beta$ depends on:\n",
    "- significance level\n",
    "- the structure of the hypothesis test (distribution, type of test, etc.)\n",
    "- the data (sample size, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Precision, recall, F-score depends on:\n",
    "- threshold\n",
    "- structure of model (type of model, hyperparameters)\n",
    "- the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Understanding model quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Want to systematically understand:\n",
    "- how changing threshold affects:\n",
    "    - true positive/false positive rate\n",
    "    - precision/recall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A nice applet. Let' play with it:\n",
    "\n",
    "http://arogozhnikov.github.io/2015/10/05/roc-curve.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tuning the tolerance (the significance level):\n",
    "- Traces out a curve in (true positive rate, false positive rate) space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Reciever Operator Characteristic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/roc_curve.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reciever operator characteristic (ROC) curve:\n",
    "- Name comes from early days of radar detection.\n",
    "- WW2 operators detecting enemy airplanes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/azm_zero.jpeg\" width = 500/></center>\n",
    "<center> Detecting the Japanese AZM Zero Fighter </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The ROC curve in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,RocCurveDisplay\n",
    "#from sklearn.metrics import plot_roc_curve #depreciated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Load in the heart disease dataset.\n",
    "[this UCI dataset](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hd_data = pd.read_csv('Data/heart.csv')\n",
    "hd_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Separate data into feature and target DataFrames\n",
    "hd_X = hd_data.drop('target', axis=1)\n",
    "hd_y = hd_data['target']\n",
    "hd_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hd_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hd_y.value_counts() # 1 = heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hd_X, hd_y, test_size=.25,\n",
    "                                                   random_state=1)\n",
    "# Scale the data for modeling\n",
    "hd_scaler = StandardScaler()\n",
    "hd_scaler.fit(X_train)\n",
    "X_train_sc = hd_scaler.transform(X_train)\n",
    "X_test_sc = hd_scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "hd_model = LogisticRegression(random_state=42)\n",
    "hd_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = hd_model.predict(X_test_sc)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we run the `.predict()` method, `sklearn` gives us the predicted values for each transaction in our test set: 0 if predicting \"no heart disease\", 1 if predicting \"heart disease\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-learn assumes a probability threshold of 0.5 on binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/sigmoid.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: the logistic regression model doesn't actually generate predicted values of 0 or 1. It creates an S-shaped curve to approximate the data, estimating the _probability_ that they belong to the target class. This probability takes a value _between_ 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The underlying predicted probability of each class given data observation\n",
    "- the .predict_proba() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_prob = hd_model.predict_proba(X_test_sc)\n",
    "y_prob[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred[:5].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Get a 2D array:\n",
    "- [P(class 0|x), P(class 1|x)] for each x in test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In principle:\n",
    "- Can change threshold cutoff to assign to given class\n",
    "- Track changes in metrics\n",
    "    - True positive/false positive rate\n",
    "    - Precision/recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### roc_curve(y_true, y_proba)\n",
    "- first argument: test values\n",
    "- second argument: probability of positive class    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- list of false positive rate (fpr)\n",
    "- list of true positive rate (tpr)\n",
    "- list of \"thresholds\" each fpr, tpr was calculated at:\n",
    "    - actually values of decision function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### True Positive Rate\n",
    "True Positive Rate (TPR) is the same as recall, measuring how many of the positive cases we correctly classified as positive.\n",
    "\n",
    "**True Positive Rate (TPR)** = **Recall** = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "Rate of correctly rejecting null (statistical power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### False Positive Rate\n",
    "False Positive Rate (FPR) measures how many of the negative casses we incorrectly classified as positive.\n",
    "\n",
    "**False Positive Rate (FPR)** = $\\frac{FP}{FP + TN}$\n",
    "\n",
    "Rate of falsely rejecting null (Type I error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given test/validation set:\n",
    "- calculate these metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### roc_curve(y_true, y_proba)\n",
    "- first argument: test values\n",
    "- second argument: probability of positive class  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- list of false positive rate (fpr)\n",
    "- list of true positive rate (tpr)\n",
    "- list of thresholds each fpr, tpr was calculated at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# use probabilty of target class\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "List of thresholds:\n",
    "- in order of: no positive identifications to always identify as positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "thresh_df = pd.DataFrame({'threshold': thresholds,\n",
    "                          'tpr':  tpr, 'fpr': fpr}).iloc[1::, :]\n",
    "thresh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "thresh_df.plot(x = 'threshold', y = 'tpr', ax = ax)\n",
    "thresh_df.plot(x = 'threshold', y = 'fpr', ax = ax)\n",
    "ax.set_ylabel('True positive rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When threshold too high:\n",
    "- Both FPR and TPR close to 0\n",
    "- Never detects positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When threshold gets lower:\n",
    "- may be increasing true positive rate\n",
    "- also increasing the rate of false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Common to plot true positive rate vs. false positive rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (9,4))\n",
    "thresh_df.plot(x = 'threshold', y = 'tpr', ax = ax[0])\n",
    "thresh_df.plot(x = 'threshold', y = 'fpr', ax = ax[0])\n",
    "thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax[1], label = 'ROC')\n",
    "ax[1].set_ylabel('True positive rate')\n",
    "ax[1].set_xlabel('False positive rate')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ROC curve\n",
    "- can be used to assess model quality: understand model behavior as a function of threshold\n",
    "- **for a given trained model and data: get threshold sweetspot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- for a given trained model and data: get threshold sweetspot\n",
    "    - high true positive rate (good statistical power)\n",
    "    - as low a false positive rate as possible (low type I error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A useful command here: \n",
    "- directly plot ROC curve\n",
    "- input our trained heart disease model and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "#plot_roc_curve(hd_model, X_test_sc, y_test);\n",
    "RocCurveDisplay.from_estimator(hd_model, X_test_sc, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lowering detection threshold:\n",
    "-  If I raise significance level, lower detection threshold:\n",
    "    - get more true positives\n",
    "    - also get more false negatives\n",
    "- Extreme case:\n",
    "    - detects everything as positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This can be used by practicioner:\n",
    "- to visually decide where to operate model threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (9,4))\n",
    "thresh_df.plot(x = 'threshold', y = 'tpr', ax = ax[0])\n",
    "thresh_df.plot(x = 'threshold', y = 'fpr', ax = ax[0])\n",
    "thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax[1], label = 'ROC')\n",
    "ax[1].set_ylabel('True positive rate')\n",
    "ax[1].set_xlabel('False positive rate')\n",
    "RocCurveDisplay.from_estimator(hd_model, X_test_sc, y_test);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Can do this visually or can use:\n",
    "- calculated TPR\n",
    "- calculated FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choose optimal threshold that maximizes:\n",
    "    \n",
    "$$ J = TPR - FPR $$\n",
    "\n",
    "Want as many true positive identifcations while minimizing false positives \n",
    "\n",
    "**Known as Youden's J-statistic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "thresh_df['J_stat'] = \\\n",
    "thresh_df['tpr'] - thresh_df['fpr']\n",
    "thresh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "thresh_df.plot(x = 'threshold', y= 'J_stat');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Select threshold with highest J-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "max_selector = thresh_df.index == thresh_df['J_stat'].idxmax()\n",
    "\n",
    "optimal_thresh = thresh_df[max_selector]\n",
    "optimal_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax, label = 'ROC')\n",
    "optimal_thresh.plot.scatter(x = 'fpr', y = 'tpr', c ='r', s = 100, ax = ax, label = 'optimal' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Make prediction at different threshold:\n",
    "- filter on threshold value other than p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "thresh = optimal_thresh['threshold'].values\n",
    "# yes...this is the way to do it for binary class.\n",
    "y_pred_with_threshold = (y_prob[:,1] >= thresh).astype(int)\n",
    "y_pred_with_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Original prediction at threshold p = 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Takeaway so far:\n",
    "- ROC can be used to visually determine best threshold to operate model at\n",
    "- Yuden's statistic can help with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ROC curve\n",
    "- **can be used to assess model quality: understand model behavior as a function of threshold**\n",
    "- for a given trained model and data: get threshold sweetspot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What does this have to do with model quality?\n",
    "- Hope is that as we change threshold we create models that typically have:\n",
    "    - higher TPR vs. FPRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Good model vs bad models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/Roc_curves_better.png\" width =600 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What affects the ROC curve?\n",
    "\n",
    "That applet again.\n",
    "\n",
    "http://arogozhnikov.github.io/2015/10/05/roc-curve.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Making good models are reflected in ROC curve structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use good distribution/function for data modeling\n",
    "    - Model selection (logistic regression, tree model, etc.)\n",
    "    - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Decrease model variance\n",
    "    - Regularization\n",
    "    - Get more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gives our ROC curve more downward L-shaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Oversampling\n",
    "\n",
    "What do you do if your model doesn't perform well due to class imbalance? One of the most effective strategies is to **oversample the minority class**. That is, I give myself more data points than I really have. I could achieve this either by [bootstrapping](https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html) or by generating some data that is fake but close to actual data. The latter is the idea behind [SMOTE](https://imbalanced-learn.org/stable/over_sampling.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ROC-AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gets the area under the ROC curve (AUC):\n",
    "- Measure of model and/or data quality\n",
    "- Bad model: AUC ~ 0.5 (area of triangle)\n",
    "- Good model: AUC $\\rightarrow$ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> Remember: If my test data comprises 90% positives and only 10% negatives, then a simple classifier that always predicts \"positive\" will be 90% accurate! And so that would be the baseline level for a classifier on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"images/auc.png\" width = 400 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/Roc_curves_better.png\" width = 400/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the probabilitiy predictions for the \"1\" class (heart disease)\n",
    "y_hat_hd = y_prob[:, 1]\n",
    "\n",
    "roc_auc_score(y_test, y_hat_hd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Very often:\n",
    "- validation tuning is done using the ROC-AUC score as metric\n",
    "- tune hyperparameters to get model class with best discriminatory power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$ k = 10$ fold cross validation:\n",
    "- use scaled train set for training/validation fold\n",
    "- scoring on the test set is now the ROC-AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "C_list = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1e3, 1e4]\n",
    "k_list = np.arange(k)\n",
    "cv_scores = []\n",
    "\n",
    "for c in C_list :\n",
    "    logreg = LogisticRegression(C = c)\n",
    "    cv_loop_results = cross_validate(\n",
    "                X=X_train_sc, \n",
    "                y=y_train,\n",
    "                estimator=logreg, \n",
    "                cv=k,\n",
    "                scoring=('roc_auc')) #the scoring is the roc auc\n",
    "    cv_scores.append(dict(zip(k_list,cv_loop_results['test_score'])))\n",
    "    \n",
    "cv_score_df = pd.DataFrame(cv_scores) \n",
    "cv_score_df['C'] = C_list\n",
    "cv_score_df.set_index('C', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cv_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# mean roc auc score\n",
    "cv_score_df.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Select $C = 0.1$ as best regularization:\n",
    "- based on ROC-AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take data with best discriminatory power: determined by ROC-AUC in validation\n",
    "- train on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "logreg_best = LogisticRegression(C = 0.1)\n",
    "logreg_best.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fitted the model with best discriminatory power:\n",
    "- now should operate machine at best threshold\n",
    "- ROC/AUC visualization and Youden's J statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Get the predicted probabilities\n",
    "- predicted class labels at threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_probs = logreg_best.predict_proba(X_test_sc)\n",
    "y_pred_probs[0:5] # print first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = logreg_best.predict(X_test_sc)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluate TPR, FPR vs threshold for class 1 detection:\n",
    "- use roc_curve() command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_best, tpr_best, thresholds_best = roc_curve(y_test, y_pred_probs[:,1])\n",
    "bestmod_thresh_df = pd.DataFrame({'threshold': thresholds_best,\n",
    "                          'tpr':  tpr_best, 'fpr': fpr_best, 'J_stat': tpr_best - fpr_best}).iloc[1::, :]\n",
    "bestmod_thresh_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Visual inspect ROC and Yuden's J maximization:\n",
    "- get best threshold to operate at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With the default parameter C = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# with default log regression\n",
    "fig, ax = plt.subplots(1,2, figsize = (9,4))\n",
    "thresh_df.plot(x = 'threshold', y = 'tpr', ax = ax[0])\n",
    "thresh_df.plot(x = 'threshold', y = 'fpr', ax = ax[0])\n",
    "thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax[1], label = 'ROC')\n",
    "ax[1].set_ylabel('True positive rate')\n",
    "ax[1].set_xlabel('False positive rate')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# C=0.1\n",
    "fig, ax = plt.subplots(1,2, figsize = (9,4))\n",
    "bestmod_thresh_df.plot(x = 'threshold', y = 'tpr', ax = ax[0])\n",
    "bestmod_thresh_df.plot(x = 'threshold', y = 'fpr', ax = ax[0])\n",
    "bestmod_thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax[1], label = 'ROC')\n",
    "ax[1].set_ylabel('True positive rate')\n",
    "ax[1].set_xlabel('False positive rate')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# with default log regression\n",
    "RocCurveDisplay.from_estimator(hd_model, X_test_sc, y_test);\n",
    "print(roc_auc_score(y_test, y_hat_hd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# C=0.1\n",
    "RocCurveDisplay.from_estimator(logreg_best, X_test_sc, y_test);\n",
    "print(roc_auc_score(y_test, y_pred_probs[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tuning and optimizing on ROC/AUC makes a difference:\n",
    "- region where we can decrease threshold (making more sensitive detector)\n",
    "- no increase in FPR, increasing TPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finding the best threshold value operating point:\n",
    "- using Yuden's J\n",
    "\n",
    "But ultimately this is up to you. Can assess visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "best_idx = bestmod_thresh_df['J_stat'].idxmax()\n",
    "best_point = pd.DataFrame(bestmod_thresh_df.iloc[best_idx]).T\n",
    "best_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using Youden's J-statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (9,4))\n",
    "bestmod_thresh_df.plot(x = 'threshold', y = 'tpr', ax = ax[0])\n",
    "bestmod_thresh_df.plot(x = 'threshold', y = 'fpr', ax = ax[0])\n",
    "ax[0].axvline(best_point['threshold'].values, c = 'r', linestyle = '--')\n",
    "\n",
    "bestmod_thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax[1], label = 'ROC')\n",
    "best_point.plot.scatter(x = 'fpr', y = 'tpr', ax = ax[1], c ='r', s = 100, label = 'Optimal')\n",
    "ax[1].set_ylabel('True positive rate')\n",
    "ax[1].set_xlabel('False positive rate')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Is this optimal? Maybe, maybe not.\n",
    "- If we care about keeping fpr low, choose threshold = 0.4 instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once satisfied with operating threshold:\n",
    "- filter probabilities according to threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#filter on class 1 probabilities\n",
    "y_pred_best_with_threshold= (y_pred_probs[:,1] >= 0.4).astype(int)\n",
    "y_pred_best_with_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's get classification report for this AUC-selected, threshold tuned model:\n",
    "- Threshold at 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_best_with_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Look at confusion matrix at this threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "conf_mat_best = confusion_matrix(y_test, y_pred_best_with_threshold)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(conf_mat_best, annot = True, ax = ax)\n",
    "ax.set_ylabel(r'$y_{true}$', size = 15)\n",
    "ax.set_xlabel(r'$y_{pred}$', size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Without any feature engineering, this is a good job.\n",
    "\n",
    "\n",
    "Instructive to look at original model performance vs. tuned/thresholded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_best_with_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_orig = hd_model.predict(X_test_sc)\n",
    "print(classification_report(y_test, y_pred_orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These kinds of considerations:\n",
    "- ROC/AUC and model discriminatory power\n",
    "- Tuning thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can be extended to multi-class problems:\n",
    "- one verse rest (OvR)\n",
    "- one verse one (OvO)\n",
    "\n",
    "Custom code needs to be built and time consuming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dplearn",
   "language": "python",
   "name": "dplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
